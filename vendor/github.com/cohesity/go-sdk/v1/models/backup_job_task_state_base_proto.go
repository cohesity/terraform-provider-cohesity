// Code generated by go-swagger; DO NOT EDIT.

package models

// This file was generated by the swagger tool.
// Editing this file might prove futile when you re-run the swagger generate command

import (
	"context"
	"strconv"

	"github.com/go-openapi/errors"
	"github.com/go-openapi/strfmt"
	"github.com/go-openapi/swag"
)

// BackupJobTaskStateBaseProto backup job task state base proto
//
// swagger:model BackupJobTaskStateBaseProto
type BackupJobTaskStateBaseProto struct {

	// The time at which the backup task was admitted to run on a Magneto slave.
	// This field will be set only after the status changes to 'kAdmitted'.
	// Using this field, amount of time spent in the waiting/queued state and the
	// amount of time taken taken to actually run the task can be determined.
	// wait time = admitted_time_usecs - start_time_usecs
	// run time = end_time_usecs - admitted_time_usecs
	//
	// Please note that this field is only set for backup task. It is not
	// applicable for the top level backup job.
	AdmittedTimeUsecs *int64 `json:"admittedTimeUsecs,omitempty"`

	// The attempt number of the job run this proto is a part of.
	AttemptNum *int32 `json:"attemptNum,omitempty"`

	// The type of the scheduled backup run.
	BackupType *int32 `json:"backupType,omitempty"`

	// If the job was cancelled, this will contain the reason for cancellation.
	CancellationReason *int32 `json:"cancellationReason,omitempty"`

	// Whether this job or task has a pending cancellation request.
	CancellationRequested *bool `json:"cancellationRequested,omitempty"`

	// Connector group id associated with the task.
	ConnectorGroupID *int64 `json:"connectorGroupId,omitempty"`

	// Whether to continue backing up on quiesce failure.
	ContinueOnQuiesceFailure *bool `json:"continueOnQuiesceFailure,omitempty"`

	// List of source ids for which source side dedup is disabled from the backup
	// job.
	DedupDisabledSourceIDVec []int64 `json:"dedupDisabledSourceIdVec"`

	// Whether or not to do brick based file backup.
	EnableBrickLevelChecksum *bool `json:"enableBrickLevelChecksum,omitempty"`

	// If status is kFinished, this field contains the end time for the backup
	// job or task.
	EndTimeUsecs *int64 `json:"endTimeUsecs,omitempty"`

	// Map from entity id to cancellation reason. This map contains the entity
	// ids of object which need to be cancel. If multiple cancellation requests
	// with different sets of entity ids will be added in this map.
	EntityIdsToCancel interface{} `json:"entityIdsToCancel,omitempty"`

	// The error encountered by this job or task instance (if any). Only valid if
	// the status of the job is kFinished.
	Error *PrivateErrorProto `json:"error,omitempty"`

	// Determines global include and exclude filters which are applied to all
	// sources in a physical backup job.
	GlobalIncludeExclude *PhysicalFileBackupParamsGlobalIncludeExclude `json:"globalIncludeExclude,omitempty"`

	// The inode id floor set on the view associated with this backup run or
	// backup task after the backup for the run or task is complete. This can be
	// used to do incremental archival of a subsequent backup run or task (by
	// only archiving those SnapTree nodes whose inode id is greater than this
	// value of this floor).
	InodeIDFloor *int64 `json:"inodeIdFloor,omitempty"`

	// Whether this is run/attempt/task was created as part of an auto protection
	// job.
	IsAutoprotect *bool `json:"isAutoprotect,omitempty"`

	// Whether this is a full or regular backup of the job/task.
	// NOTE: This can possibly be set to true even if the scheduled backup type
	// is kRegular (e.g., when this corresponds to the first backup run of the
	// job/task or if no previous snapshot information is found).
	IsFullBackup *bool `json:"isFullBackup,omitempty"`

	// Specifies whether the tiering goal has been met.
	IsTieringGoalMet *bool `json:"isTieringGoalMet,omitempty"`

	// The id of the locally created job whose data this proto represents. This
	// field should only be used for jobs created on the local cluster. For jobs
	// created remotely, the job_uid field below should be used.
	JobID *int64 `json:"jobId,omitempty"`

	// A cluster wide unique instance id. Each time a job is run it gets a new
	// instance id. This helps identify different runs of a job.
	JobInstanceID *int64 `json:"jobInstanceId,omitempty"`

	// The globally unique id of the job whose data this proto represents.
	JobUID *UniversalIDProto `json:"jobUid,omitempty"`

	// This is a run sequencer which will incremented whenever run reaches a new
	// milestone. A milestone can be a change in state, or attempts, progress
	// percentage incrementals (e.g. 10%), This will be used by Helios ETL to
	// identify the latest copy of the backup run.
	LastUpdateLogicalTimestamp *int64 `json:"lastUpdateLogicalTimestamp,omitempty"`

	// Network realm id associated with the task.
	NetworkRealmID *int64 `json:"networkRealmId,omitempty"`

	// The pause state of the protection group run or task. This field will be
	// populated throughout the life of job run or task.
	PauseState *BackupJobTaskStateBaseProtoPauseState `json:"pauseState,omitempty"`

	// Whether or not to do brick based dedup.
	PerformBrickBasedDedup *bool `json:"performBrickBasedDedup,omitempty"`

	// Whether or not to do source side dedup.
	PerformSourceSideDedup *bool `json:"performSourceSideDedup,omitempty"`

	// Denotes time when gatekeeper permit is granted to the backup task. If the
	// backup task is rescheduled on new slave due to errors, the field is
	// updated to time when permit is granted again.
	PermitGrantTimeUsecs *int64 `json:"permitGrantTimeUsecs,omitempty"`

	// Field to indicate whether parallel backup is enabled for physical files
	PhysicalFileParallelBackupEnabled *bool `json:"physicalFileParallelBackupEnabled,omitempty"`

	// The globally unique id of the original remote job from which this job
	// (whose data this proto represents) was derived.
	PrimaryJobUID *UniversalIDProto `json:"primaryJobUid,omitempty"`

	// This field means slightly different things depending on the type of
	// proto this base proto is a member of:
	// If this is a member of BackupJobAttemptStateProto, the value refers to
	// the root path of a Pulse task tracking the progress of a backup run
	// attempt.
	// If this is a member of BackupJobRunStateProto, the field is not set.
	// If this is a member of BackupTaskStateProto, the value refers to
	// the full path of a Pulse task tracking the progress of backup of an
	// individual object (i.e, VM in vmware env) within that backup run.
	ProgressMonitorTaskPath *string `json:"progressMonitorTaskPath,omitempty"`

	// Iris-facing task state. This field is stamped during the export.
	PublicStatus *int32 `json:"publicStatus,omitempty"`

	// Whether to take app-consistent snapshots by quiescing apps and the
	// filesystem before taking a backup.
	Quiesce *bool `json:"quiesce,omitempty"`

	// SLA deadline implied by protection policy, if applicable.
	// For RPO jobs, this is the RPO deadline.
	SLADeadlineTimeUsecs *int64 `json:"slaDeadlineTimeUsecs,omitempty"`

	// True if the job SLA was violated. Only valid if status is kFinished.
	SLAViolated *bool `json:"slaViolated,omitempty"`

	// Determines include and exclude filters which are applied to entities in
	// a backup source. For SQL, this will be applicable only for auto protect
	// sources.
	SourceFilters *SourceFilters `json:"sourceFilters,omitempty"`

	// A list of sources being protected, along with the scheduled time for which
	// it is being backed up.
	Sources []*BackupJobTaskStateBaseProtoSourceState `json:"sources"`

	// The start time for this backup job or task.
	StartTimeUsecs *int64 `json:"startTimeUsecs,omitempty"`

	// Id of the Stats counter used to track the physical bytes written by the
	// backup task or the backup attempt. This field is not populated if this
	// proto is part of BackupJobRunStateProto.
	StatsCounterID *string `json:"statsCounterId,omitempty"`

	// Current state of the job or task.
	Status *int32 `json:"status,omitempty"`

	// Denotes time when gatekeeper permit is granted to the backup subtask. The
	// key of map is subtask id  and value is time when the permit was granted to
	// subtask.
	// TODO(prem): Get rid after removing all references.
	SubtaskToPermitGrantTimeUsecsMapDEPRECATED interface{} `json:"subtaskToPermitGrantTimeUsecsMap_DEPRECATED,omitempty"`

	// List of successfully protected entities by the task.
	SuccessfullyProtectedEntities []*PrivateEntityProto `json:"successfullyProtectedEntities"`

	// Total amount of data read from the source of the backup (so far).
	TotalBytesReadFromSource *int64 `json:"totalBytesReadFromSource,omitempty"`

	// Total amount of data successfully tiered from the NAS source.
	TotalBytesTiered *int64 `json:"totalBytesTiered,omitempty"`

	// Total amount of data to be read from the source of the backup. This field
	// is set only if this base proto is a member of a BackupTaskStateProto.
	TotalBytesToReadFromSource *int64 `json:"totalBytesToReadFromSource,omitempty"`

	// Logical size of this backup job or task. This is the amount of data we
	// would have read from the source(s) had this been a full backup.
	TotalLogicalBackupSizeBytes *int64 `json:"totalLogicalBackupSizeBytes,omitempty"`

	// Total amount of time a task/run has been in paused state. This information
	// along with start_time_usecs, will be used to calculate the active running
	// duration of a backup run/task.
	TotalPauseTimeUsecs *int64 `json:"totalPauseTimeUsecs,omitempty"`

	// Total amount of physical space used by Cohesity to store this backup job
	// or task. Savings achieved from all underlying storage technologies
	// (including things like compression, and deduplication) is taken into
	// account. To give a concrete example, if the logical backup size is 1GB,
	// but only 1MB was used by Cohesity to store it (as the rest of the data
	// was de-duplicated), this variable would reflect 1MB.
	//
	// This value means slightly different things depending on the type of
	// proto this base proto is a member of:
	// If this is a member of BackupJobAttemptStateProto, this value reflects
	// the total physical space used by a specific job run attempt.
	// If this is a member of BackupJobRunStateProto, this value reflects
	// the total physical space used across all attempts in the job run.
	// If this is a member of BackupTaskStateProto, this value reflects the
	// cumulative total physical space used by that task.
	//
	// This value might change over time even after a job run finishes,
	// e.g., if bridge performs post-dedup. However the expectation is that
	// after some time, this value will become relatively stable (when it is a
	// member of BackupJobAttemptStateProto).
	TotalPhysicalBackupSizeBytes *int64 `json:"totalPhysicalBackupSizeBytes,omitempty"`

	// The size of the source being backed up in this backup job or task. Size of
	// a leaf level source/entity in the backup task is used to determine the
	// weight to be assigned to that task in the backup job progress monitor.
	// Please note that value of this field is based on the size of the VM disks
	// before any snapshot is taken, while the value of the below field
	// 'total_logical_backup_size_bytes' is based on the size of the VM disks
	// after the snapshot is taken.
	TotalSourceSizeBytes *int64 `json:"totalSourceSizeBytes,omitempty"`

	// In some apps, the usage size may differ from the logical size
	// E.g. in SQL the file is pre-allocated. In that case the usage
	// of actual data in the file maybe lower than the file size
	TotalUsageSizeBytes *int64 `json:"totalUsageSizeBytes,omitempty"`

	// The type of environment that the job/task is operating on.
	Type *int32 `json:"type,omitempty"`

	// A message displayed to the user for this job or task instance (if any).
	// Only valid if the status of the job is kFinished. This is used for
	// informing the user about a finished job or task, when there is not an
	// error.
	UserMessage *string `json:"userMessage,omitempty"`

	// The view box to which backed up data must be saved.
	ViewBoxID *int64 `json:"viewBoxId,omitempty"`

	// The view name where snapshots will be kept for this backup run or backup
	// task. This will not be set for some environments like kView and
	// kPuppeteer. If this is not set for other supported environments, a default
	// view for the environment will be used.
	ViewName *string `json:"viewName,omitempty"`

	// Details of why the task is waiting, this is set when the task is waiting.
	// This is only considered when status is kReadyToSchedule. This is currently
	// populated when this task is waiting for a task in an older run to finish.
	// This might happen becuase we have parallel runs and the older task is
	// holding lock on the entity to be backed up.
	WaitingReason *string `json:"waitingReason,omitempty"`

	// The warnings encountered by this job or task instance (if any) during the
	// backup run.
	Warnings []*PrivateErrorProto `json:"warnings"`
}

// Validate validates this backup job task state base proto
func (m *BackupJobTaskStateBaseProto) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateError(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateGlobalIncludeExclude(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateJobUID(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validatePauseState(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validatePrimaryJobUID(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateSourceFilters(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateSources(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateSuccessfullyProtectedEntities(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateWarnings(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *BackupJobTaskStateBaseProto) validateError(formats strfmt.Registry) error {
	if swag.IsZero(m.Error) { // not required
		return nil
	}

	if m.Error != nil {
		if err := m.Error.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("error")
			} else if ce, ok := err.(*errors.CompositeError); ok {
				return ce.ValidateName("error")
			}
			return err
		}
	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) validateGlobalIncludeExclude(formats strfmt.Registry) error {
	if swag.IsZero(m.GlobalIncludeExclude) { // not required
		return nil
	}

	if m.GlobalIncludeExclude != nil {
		if err := m.GlobalIncludeExclude.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("globalIncludeExclude")
			} else if ce, ok := err.(*errors.CompositeError); ok {
				return ce.ValidateName("globalIncludeExclude")
			}
			return err
		}
	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) validateJobUID(formats strfmt.Registry) error {
	if swag.IsZero(m.JobUID) { // not required
		return nil
	}

	if m.JobUID != nil {
		if err := m.JobUID.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("jobUid")
			} else if ce, ok := err.(*errors.CompositeError); ok {
				return ce.ValidateName("jobUid")
			}
			return err
		}
	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) validatePauseState(formats strfmt.Registry) error {
	if swag.IsZero(m.PauseState) { // not required
		return nil
	}

	if m.PauseState != nil {
		if err := m.PauseState.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("pauseState")
			} else if ce, ok := err.(*errors.CompositeError); ok {
				return ce.ValidateName("pauseState")
			}
			return err
		}
	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) validatePrimaryJobUID(formats strfmt.Registry) error {
	if swag.IsZero(m.PrimaryJobUID) { // not required
		return nil
	}

	if m.PrimaryJobUID != nil {
		if err := m.PrimaryJobUID.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("primaryJobUid")
			} else if ce, ok := err.(*errors.CompositeError); ok {
				return ce.ValidateName("primaryJobUid")
			}
			return err
		}
	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) validateSourceFilters(formats strfmt.Registry) error {
	if swag.IsZero(m.SourceFilters) { // not required
		return nil
	}

	if m.SourceFilters != nil {
		if err := m.SourceFilters.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("sourceFilters")
			} else if ce, ok := err.(*errors.CompositeError); ok {
				return ce.ValidateName("sourceFilters")
			}
			return err
		}
	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) validateSources(formats strfmt.Registry) error {
	if swag.IsZero(m.Sources) { // not required
		return nil
	}

	for i := 0; i < len(m.Sources); i++ {
		if swag.IsZero(m.Sources[i]) { // not required
			continue
		}

		if m.Sources[i] != nil {
			if err := m.Sources[i].Validate(formats); err != nil {
				if ve, ok := err.(*errors.Validation); ok {
					return ve.ValidateName("sources" + "." + strconv.Itoa(i))
				} else if ce, ok := err.(*errors.CompositeError); ok {
					return ce.ValidateName("sources" + "." + strconv.Itoa(i))
				}
				return err
			}
		}

	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) validateSuccessfullyProtectedEntities(formats strfmt.Registry) error {
	if swag.IsZero(m.SuccessfullyProtectedEntities) { // not required
		return nil
	}

	for i := 0; i < len(m.SuccessfullyProtectedEntities); i++ {
		if swag.IsZero(m.SuccessfullyProtectedEntities[i]) { // not required
			continue
		}

		if m.SuccessfullyProtectedEntities[i] != nil {
			if err := m.SuccessfullyProtectedEntities[i].Validate(formats); err != nil {
				if ve, ok := err.(*errors.Validation); ok {
					return ve.ValidateName("successfullyProtectedEntities" + "." + strconv.Itoa(i))
				} else if ce, ok := err.(*errors.CompositeError); ok {
					return ce.ValidateName("successfullyProtectedEntities" + "." + strconv.Itoa(i))
				}
				return err
			}
		}

	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) validateWarnings(formats strfmt.Registry) error {
	if swag.IsZero(m.Warnings) { // not required
		return nil
	}

	for i := 0; i < len(m.Warnings); i++ {
		if swag.IsZero(m.Warnings[i]) { // not required
			continue
		}

		if m.Warnings[i] != nil {
			if err := m.Warnings[i].Validate(formats); err != nil {
				if ve, ok := err.(*errors.Validation); ok {
					return ve.ValidateName("warnings" + "." + strconv.Itoa(i))
				} else if ce, ok := err.(*errors.CompositeError); ok {
					return ce.ValidateName("warnings" + "." + strconv.Itoa(i))
				}
				return err
			}
		}

	}

	return nil
}

// ContextValidate validate this backup job task state base proto based on the context it is used
func (m *BackupJobTaskStateBaseProto) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateError(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateGlobalIncludeExclude(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateJobUID(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidatePauseState(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidatePrimaryJobUID(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateSourceFilters(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateSources(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateSuccessfullyProtectedEntities(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateWarnings(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *BackupJobTaskStateBaseProto) contextValidateError(ctx context.Context, formats strfmt.Registry) error {

	if m.Error != nil {

		if swag.IsZero(m.Error) { // not required
			return nil
		}

		if err := m.Error.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("error")
			} else if ce, ok := err.(*errors.CompositeError); ok {
				return ce.ValidateName("error")
			}
			return err
		}
	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) contextValidateGlobalIncludeExclude(ctx context.Context, formats strfmt.Registry) error {

	if m.GlobalIncludeExclude != nil {

		if swag.IsZero(m.GlobalIncludeExclude) { // not required
			return nil
		}

		if err := m.GlobalIncludeExclude.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("globalIncludeExclude")
			} else if ce, ok := err.(*errors.CompositeError); ok {
				return ce.ValidateName("globalIncludeExclude")
			}
			return err
		}
	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) contextValidateJobUID(ctx context.Context, formats strfmt.Registry) error {

	if m.JobUID != nil {

		if swag.IsZero(m.JobUID) { // not required
			return nil
		}

		if err := m.JobUID.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("jobUid")
			} else if ce, ok := err.(*errors.CompositeError); ok {
				return ce.ValidateName("jobUid")
			}
			return err
		}
	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) contextValidatePauseState(ctx context.Context, formats strfmt.Registry) error {

	if m.PauseState != nil {

		if swag.IsZero(m.PauseState) { // not required
			return nil
		}

		if err := m.PauseState.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("pauseState")
			} else if ce, ok := err.(*errors.CompositeError); ok {
				return ce.ValidateName("pauseState")
			}
			return err
		}
	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) contextValidatePrimaryJobUID(ctx context.Context, formats strfmt.Registry) error {

	if m.PrimaryJobUID != nil {

		if swag.IsZero(m.PrimaryJobUID) { // not required
			return nil
		}

		if err := m.PrimaryJobUID.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("primaryJobUid")
			} else if ce, ok := err.(*errors.CompositeError); ok {
				return ce.ValidateName("primaryJobUid")
			}
			return err
		}
	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) contextValidateSourceFilters(ctx context.Context, formats strfmt.Registry) error {

	if m.SourceFilters != nil {

		if swag.IsZero(m.SourceFilters) { // not required
			return nil
		}

		if err := m.SourceFilters.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("sourceFilters")
			} else if ce, ok := err.(*errors.CompositeError); ok {
				return ce.ValidateName("sourceFilters")
			}
			return err
		}
	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) contextValidateSources(ctx context.Context, formats strfmt.Registry) error {

	for i := 0; i < len(m.Sources); i++ {

		if m.Sources[i] != nil {

			if swag.IsZero(m.Sources[i]) { // not required
				return nil
			}

			if err := m.Sources[i].ContextValidate(ctx, formats); err != nil {
				if ve, ok := err.(*errors.Validation); ok {
					return ve.ValidateName("sources" + "." + strconv.Itoa(i))
				} else if ce, ok := err.(*errors.CompositeError); ok {
					return ce.ValidateName("sources" + "." + strconv.Itoa(i))
				}
				return err
			}
		}

	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) contextValidateSuccessfullyProtectedEntities(ctx context.Context, formats strfmt.Registry) error {

	for i := 0; i < len(m.SuccessfullyProtectedEntities); i++ {

		if m.SuccessfullyProtectedEntities[i] != nil {

			if swag.IsZero(m.SuccessfullyProtectedEntities[i]) { // not required
				return nil
			}

			if err := m.SuccessfullyProtectedEntities[i].ContextValidate(ctx, formats); err != nil {
				if ve, ok := err.(*errors.Validation); ok {
					return ve.ValidateName("successfullyProtectedEntities" + "." + strconv.Itoa(i))
				} else if ce, ok := err.(*errors.CompositeError); ok {
					return ce.ValidateName("successfullyProtectedEntities" + "." + strconv.Itoa(i))
				}
				return err
			}
		}

	}

	return nil
}

func (m *BackupJobTaskStateBaseProto) contextValidateWarnings(ctx context.Context, formats strfmt.Registry) error {

	for i := 0; i < len(m.Warnings); i++ {

		if m.Warnings[i] != nil {

			if swag.IsZero(m.Warnings[i]) { // not required
				return nil
			}

			if err := m.Warnings[i].ContextValidate(ctx, formats); err != nil {
				if ve, ok := err.(*errors.Validation); ok {
					return ve.ValidateName("warnings" + "." + strconv.Itoa(i))
				} else if ce, ok := err.(*errors.CompositeError); ok {
					return ce.ValidateName("warnings" + "." + strconv.Itoa(i))
				}
				return err
			}
		}

	}

	return nil
}

// MarshalBinary interface implementation
func (m *BackupJobTaskStateBaseProto) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *BackupJobTaskStateBaseProto) UnmarshalBinary(b []byte) error {
	var res BackupJobTaskStateBaseProto
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}
